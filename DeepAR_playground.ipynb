{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQyOudRcMXe",
        "outputId": "de23b647-f5d8-4359-b774-76a647323da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'deepar'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 176 (delta 44), reused 53 (delta 29), pack-reused 89 (from 1)\u001b[K\n",
            "Receiving objects: 100% (176/176), 84.11 KiB | 1.62 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Olyco/deepar.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-BkzG8f1oIG",
        "outputId": "2e9e4ce8-15e8-4477-ab5f-8b2b7057e5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 6)) (8.3.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r deepar/requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r deepar/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r deepar/requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (0.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r deepar/requirements.txt (line 4)) (0.45.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->-r deepar/requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->-r deepar/requirements.txt (line 7)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->-r deepar/requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.0.2)\n",
            "Collecting tkan\n",
            "  Downloading tkan-0.4.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: keras<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tkan) (3.8.0)\n",
            "Collecting keras_efficient_kan<0.2.0,>=0.1.9 (from tkan)\n",
            "  Downloading keras_efficient_kan-0.1.10-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras<4.0.0,>=3.0.0->tkan) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras<4.0.0,>=3.0.0->tkan) (0.1.2)\n",
            "Downloading tkan-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Downloading keras_efficient_kan-0.1.10-py3-none-any.whl (3.5 kB)\n",
            "Installing collected packages: keras_efficient_kan, tkan\n",
            "Successfully installed keras_efficient_kan-0.1.10 tkan-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r deepar/requirements.txt\n",
        "!pip install tkan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsNRwFh_DYLX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EuPhEPuJ6t1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "TojYcp6RCzMC"
      },
      "outputs": [],
      "source": [
        "#@title датасет\n",
        "from abc import ABC\n",
        "\n",
        "\n",
        "class Dataset(ABC):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def next_batch(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(\"deepar\")\n",
        "\n",
        "\n",
        "class MockTs(Dataset):\n",
        "    \"\"\"\n",
        "    This class generates 'mock' time series data of the form (y = t * np.sin(t/6) / 3 +np.sin(t*2))\n",
        "    Created mainly for showcase/testing purpose\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dimensions=1, t_min=0, t_max=30, resolution=0.1, batch_size=1, n_steps=10\n",
        "    ):\n",
        "        self.dimensions = dimensions\n",
        "        self.t_min = t_min\n",
        "        self.t_max = t_max\n",
        "        self.resolution = resolution\n",
        "        self.data = True\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    @staticmethod\n",
        "    def _time_series(t):\n",
        "        return t * np.sin(t / 6) / 3 + np.sin(t * 2)\n",
        "\n",
        "    def next_batch(self, batch_size, n_steps):\n",
        "        \"\"\"\n",
        "        Generate next batch (x, y), generate y by lagging x (1 step)\n",
        "        \"\"\"\n",
        "        Y = []\n",
        "        for dim in range(self.dimensions):\n",
        "            t0 = np.random.rand(batch_size, 1) * (\n",
        "                self.t_max - self.t_min - n_steps * self.resolution\n",
        "            )\n",
        "            Ts = t0 + np.arange(0.0, n_steps + 1) * self.resolution\n",
        "            ys = self._time_series(Ts)\n",
        "            Y.append(ys[:, :-1].reshape(-1, n_steps, 1))\n",
        "        return np.concatenate(Y, axis=2), np.concatenate(Y, axis=2)\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Iterator.\"\"\"\n",
        "        return self.next_batch(n_steps=self.n_steps, batch_size=self.batch_size)\n",
        "\n",
        "    @property\n",
        "    def mock_ts(self):\n",
        "        \"\"\"\n",
        "        Return the data used for training (ranging from self.t_min and self.t_max, with resolution self.resolution)\n",
        "        :return: a Numpy array\n",
        "        \"\"\"\n",
        "        t_list = [self.t_min]\n",
        "        results = [self._time_series(t_list[0])]\n",
        "        while t_list[-1] < self.t_max:\n",
        "            t_list.append(t_list[-1] + self.resolution)\n",
        "            results.append(self._time_series(t_list[-1]))\n",
        "        return results\n",
        "\n",
        "    def generate_test_data(self, n_steps):\n",
        "        \"\"\"\n",
        "        Generate test data outside of the training set (t > self.t_max)\n",
        "        :param n_steps:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        t_list = [self.t_max + self.resolution]\n",
        "        results = [self._time_series(t_list[0])]\n",
        "        for i in range(1, n_steps):\n",
        "            t_list.append(t_list[-1] + self.resolution)\n",
        "            results.append(self._time_series(t_list[-1]))\n",
        "        return results\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "class TimeSeries(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pandas_df,\n",
        "        one_hot_root_list=None,\n",
        "        grouping_variable=\"category\",\n",
        "        scaler=None,\n",
        "        n_steps=1,\n",
        "        batch_size=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.data = pandas_df\n",
        "        self.one_hot_root_list = one_hot_root_list\n",
        "        self.grouping_variable = grouping_variable\n",
        "        if self.data is None:\n",
        "            raise ValueError(\"Must provide a Pandas df to instantiate this class\")\n",
        "        self.scaler = scaler\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Iterator.\"\"\"\n",
        "        return self.next_batch(n_steps=self.n_steps, batch_size=self.batch_size)\n",
        "\n",
        "    def _one_hot_padding(self, pandas_df, padding_df):\n",
        "        \"\"\"\n",
        "        Util padding function\n",
        "        :param padding_df:\n",
        "        :param one_hot_root_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for one_hot_root in self.one_hot_root_list:\n",
        "            one_hot_columns = [\n",
        "                i\n",
        "                for i in pandas_df.columns  # select columns equal to 1\n",
        "                if i.startswith(one_hot_root) and pandas_df[i].values[0] == 1\n",
        "            ]\n",
        "            for col in one_hot_columns:\n",
        "                padding_df[col] = 1\n",
        "        return padding_df\n",
        "\n",
        "    def _pad_ts(self, pandas_df, desired_len, padding_val=0):\n",
        "        \"\"\"\n",
        "        Add padding int to the time series\n",
        "        :param pandas_df:\n",
        "        :param desired_len: (int)\n",
        "        :param padding_val: (int)\n",
        "        :return: X (feature_space), y\n",
        "        \"\"\"\n",
        "        pad_length = desired_len - pandas_df.shape[0]\n",
        "        padding_df = pd.concat(\n",
        "            [\n",
        "                pd.DataFrame(\n",
        "                    {col: padding_val for col in pandas_df.columns},\n",
        "                    index=[i for i in range(pad_length)],\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if self.one_hot_root_list:\n",
        "            padding_df = self._one_hot_padding(pandas_df, padding_df)\n",
        "\n",
        "        return pd.concat([padding_df, pandas_df]).reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def _sample_ts(pandas_df, desired_len):\n",
        "        \"\"\"\n",
        "\n",
        "        :param pandas_df: input pandas df with 'target' columns e features\n",
        "        :param desired_len: desired sample length (number of rows)\n",
        "        :param padding_val: default is 0\n",
        "        :param initial_obs: how many observations to skip at the beginning\n",
        "        :return: a pandas df (sample)\n",
        "        \"\"\"\n",
        "        if pandas_df.shape[0] < desired_len:\n",
        "            raise ValueError(\"Desired sample length is greater than df row len\")\n",
        "        if pandas_df.shape[0] == desired_len:\n",
        "            return pandas_df\n",
        "\n",
        "        start_index = np.random.choice(\n",
        "            [i for i in range(0, pandas_df.shape[0] - desired_len + 1)]\n",
        "        )\n",
        "        return pandas_df.iloc[\n",
        "            start_index : start_index + desired_len,\n",
        "        ]\n",
        "\n",
        "    def next_batch(\n",
        "        self, batch_size, n_steps, target_var=\"target\", verbose=False, padding_value=0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param batch_size: how many time series to be sampled in this batch (int)\n",
        "        :param n_steps: how many RNN cells (int)\n",
        "        :param target_var: (str)\n",
        "        :param verbose: (boolean)\n",
        "        :param padding_value: (float)\n",
        "        :return: X (feature space), y\n",
        "        \"\"\"\n",
        "\n",
        "        # Select n_batch time series\n",
        "        groups_list = self.data[self.grouping_variable].unique()\n",
        "        np.random.shuffle(groups_list)\n",
        "        selected_groups = groups_list[:batch_size]\n",
        "        input_data = self.data[\n",
        "            self.data[self.grouping_variable].isin(set(selected_groups))\n",
        "        ]\n",
        "\n",
        "        # Initial padding for each selected time series to reach n_steps\n",
        "        sampled = []\n",
        "        for cat, cat_data in input_data.groupby(self.grouping_variable):\n",
        "            if cat_data.shape[0] < n_steps:\n",
        "                sampled_cat_data = self._pad_ts(\n",
        "                    pandas_df=cat_data, desired_len=n_steps, padding_val=padding_value\n",
        "                )\n",
        "            else:\n",
        "                sampled_cat_data = self._sample_ts(\n",
        "                    pandas_df=cat_data, desired_len=n_steps\n",
        "                )\n",
        "            sampled.append(sampled_cat_data)\n",
        "            if verbose:\n",
        "                logger.debug(\"Sampled data for {}\".format(cat))\n",
        "                logger.debug(sampled_cat_data)\n",
        "        rnn_output = (\n",
        "            pd.concat(sampled)\n",
        "            .drop(columns=self.grouping_variable)\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        if self.scaler:\n",
        "            batch_scaler = self.scaler()\n",
        "            n_rows = rnn_output.shape[0]\n",
        "            # Scaling will have to be extended to handle multiple variables!\n",
        "            rnn_output[\"feature_1\"] = rnn_output.feature_1.astype(\"float\")\n",
        "            rnn_output[target_var] = rnn_output[target_var].astype(\"float\")\n",
        "\n",
        "            rnn_output[\"feature_1\"] = batch_scaler.fit_transform(\n",
        "                rnn_output.feature_1.values.reshape(n_rows, 1)\n",
        "            ).reshape(n_rows)\n",
        "            rnn_output[target_var] = batch_scaler.fit_transform(\n",
        "                rnn_output[target_var].values.reshape(n_rows, 1)\n",
        "            ).reshape(n_rows)\n",
        "\n",
        "        return (\n",
        "            rnn_output.drop(target_var, 1).values.reshape(batch_size, n_steps, -1),\n",
        "            rnn_output[target_var].values.reshape(batch_size, n_steps, 1),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "VQmyLmmfC9ou"
      },
      "outputs": [],
      "source": [
        "#@title модель\n",
        "from abc import ABC\n",
        "\n",
        "\n",
        "class NNModel(ABC):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def net_structure(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def instantiate_and_fit(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "class GaussianLayer(Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        \"\"\"Init.\"\"\"\n",
        "        self.output_dim = output_dim\n",
        "        self.kernel_1, self.kernel_2, self.bias_1, self.bias_2 = [], [], [], []\n",
        "        super(GaussianLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build the weights and biases.\"\"\"\n",
        "        n_weight_rows = input_shape[2]\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            name=\"kernel_1\",\n",
        "            shape=(n_weight_rows, self.output_dim),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.kernel_2 = self.add_weight(\n",
        "            name=\"kernel_2\",\n",
        "            shape=(n_weight_rows, self.output_dim),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.bias_1 = self.add_weight(\n",
        "            name=\"bias_1\",\n",
        "            shape=(self.output_dim,),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.bias_2 = self.add_weight(\n",
        "            name=\"bias_2\",\n",
        "            shape=(self.output_dim,),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        super(GaussianLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Do the layer computation.\"\"\"\n",
        "        output_mu = K.dot(x, self.kernel_1) + self.bias_1\n",
        "        output_sig = K.dot(x, self.kernel_2) + self.bias_2\n",
        "        output_sig_pos = K.log(1 + K.exp(output_sig)) + 1e-06\n",
        "        return [output_mu, output_sig_pos]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Calculate the output dimensions.\n",
        "\n",
        "        The assumption here is that the output ts is always one-dimensional;\n",
        "        \"\"\"\n",
        "        return [(input_shape[0], self.output_dim), (input_shape[0], self.output_dim)]\n",
        "\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf.keras.layers import Layer, Lambda\n",
        "from tf.keras import backend as K\n",
        "\n",
        "from keras.losses import Loss\n",
        "\n",
        "class GaussianLikelihood(Loss):\n",
        "    def __init__(self, sigma, **kwargs):\n",
        "        super(self).__init__(**kwargs)\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y_true, y_pred = inputs\n",
        "        loss = (\n",
        "            tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "            + tf.math.log(self.sigma)\n",
        "            + tf.math.truediv(\n",
        "                tf.math.square(y_true - y_pred),\n",
        "                2 * tf.math.square(self.sigma)\n",
        "            )\n",
        "        )\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "# class GaussianLikelihood(Layer):\n",
        "#     def __init__(self, sigma, **kwargs):\n",
        "#         super(GaussianLikelihood, self).__init__(**kwargs)\n",
        "#         self.sigma = sigma\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         y_true, y_pred = inputs\n",
        "#         loss = (\n",
        "#             tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "#             + tf.math.log(self.sigma)\n",
        "#             + tf.math.truediv(\n",
        "#                 tf.math.square(y_true - y_pred),\n",
        "#                 2 * tf.math.square(self.sigma)\n",
        "#             )\n",
        "#         )\n",
        "#         return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "# def gaussian_likelihood(sigma):\n",
        "#     \"\"\"Likelihood as per the paper.\"\"\"\n",
        "\n",
        "#     def gaussian_loss(y_true, y_pred):\n",
        "#         \"\"\"Updated from paper.\n",
        "\n",
        "#         See DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks.\n",
        "#         \"\"\"\n",
        "\n",
        "#         return tf.reduce_mean(\n",
        "#             tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "#             + tf.math.log(sigma)\n",
        "#             + tf.math.truediv(\n",
        "#                 tf.math.square(y_true - y_pred), 2 * tf.math.square(sigma)\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#     return gaussian_loss\n",
        "\n",
        "\n",
        "import math\n",
        "from functools import partial\n",
        "import logging\n",
        "from typing import Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# from deepar.model.loss import gaussian_likelihood\n",
        "# from deepar.model import NNModel\n",
        "# from deepar.model.layers import GaussianLayer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class DeepAR(NNModel):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ts_obj,\n",
        "        steps_per_epoch=50,\n",
        "        epochs=100,\n",
        "        loss=gaussian_likelihood,\n",
        "        optimizer=\"adam\",\n",
        "        with_custom_nn_structure=None,\n",
        "    ):\n",
        "        \"\"\"Init.\"\"\"\n",
        "\n",
        "        self.ts_obj = ts_obj\n",
        "        self.inputs, self.z_sample = None, None\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.epochs = epochs\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.keras_model = None\n",
        "        if with_custom_nn_structure:\n",
        "            self.nn_structure = with_custom_nn_structure\n",
        "        else:\n",
        "            self.nn_structure = partial(\n",
        "                DeepAR.basic_structure,\n",
        "                n_steps=self.ts_obj.n_steps,\n",
        "                dimensions=self.ts_obj.dimensions,\n",
        "            )\n",
        "        self._output_layer_name = \"main_output\"\n",
        "        self.get_intermediate = None\n",
        "\n",
        "    @staticmethod\n",
        "    def basic_structure(n_steps=20, dimensions=1):\n",
        "        \"\"\"\n",
        "        This is the method that needs to be patched when changing NN structure\n",
        "        :return: inputs_shape (tuple), inputs (Tensor), [loc, scale] (a list of theta parameters\n",
        "        of the target likelihood).\n",
        "\n",
        "        Please note that I've made up scaling rules of the hidden layer dimensions.\n",
        "        \"\"\"\n",
        "        input_shape = (n_steps, dimensions)\n",
        "        inputs = Input(shape=input_shape)\n",
        "        x = LSTM(\n",
        "            int(4 * (1 + math.pow(math.log(dimensions), 4))),\n",
        "            return_sequences=True,\n",
        "            dropout=0.1,\n",
        "        )(inputs)\n",
        "        x = Dense(int(4 * (1 + math.log(dimensions))), activation=\"relu\")(x)\n",
        "        loc, scale = GaussianLayer(dimensions, name=\"main_output\")(x)\n",
        "        return input_shape, inputs, [loc, scale]\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        epochs: Optional[int] = None,\n",
        "        verbose: Union[str, int] = \"auto\",\n",
        "        patience: int = 10,\n",
        "    ):\n",
        "        \"\"\"Fit model.\n",
        "\n",
        "        This is called from instantiate and fit().\n",
        "\n",
        "        Args:\n",
        "            epochs (Optional[int]): number of epochs to train. If nothing\n",
        "                defined, take self.epochs. Please the early stopping (patience).\n",
        "            verbose (Union[str, int]): passed to keras.fit(). Can be\n",
        "                \"auto\", 0, or 1.\n",
        "            patience (int): Number of epochs without without improvement to stop.\n",
        "        \"\"\"\n",
        "        if not epochs:\n",
        "            epochs = self.epochs\n",
        "        callback = callbacks.EarlyStopping(monitor=\"loss\", patience=patience)\n",
        "        self.keras_model.fit(\n",
        "            ts_generator(self.ts_obj, self.ts_obj.n_steps),\n",
        "            steps_per_epoch=self.steps_per_epoch,\n",
        "            epochs=epochs,\n",
        "            verbose=verbose,\n",
        "            callbacks=[callback],\n",
        "        )\n",
        "        if verbose:\n",
        "            logger.debug(\"Model was successfully trained\")\n",
        "        self.get_intermediate = K.function(\n",
        "            inputs=[self.keras_model.input],\n",
        "            outputs=self.keras_model.get_layer(self._output_layer_name).output,\n",
        "        )\n",
        "\n",
        "    def build_model(self):\n",
        "        input_shape, inputs, theta = self.nn_structure()\n",
        "        model = Model(inputs, theta[0])\n",
        "        model.compile(loss=self.loss(theta[1]), optimizer=self.optimizer)\n",
        "        self.keras_model = model\n",
        "\n",
        "    def instantiate_and_fit(\n",
        "        self,\n",
        "        epochs: Optional[int] = None,\n",
        "        verbose: Union[str, int] = \"auto\",\n",
        "        do_fit: bool = True,\n",
        "    ):\n",
        "        \"\"\"Compile and train model.\"\"\"\n",
        "        self.build_model()\n",
        "        self.fit(verbose=verbose, epochs=epochs)\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.keras_model\n",
        "\n",
        "    def predict_theta_from_input(self, input_list):\n",
        "        \"\"\"\n",
        "        This function takes an input of size equal to the n_steps specified in 'Input' when building the\n",
        "        network\n",
        "        :param input_list:\n",
        "        :return: [[]], a list of list. E.g. when using Gaussian layer this returns a list of two list,\n",
        "        corresponding to [[mu_values], [sigma_values]]\n",
        "        \"\"\"\n",
        "        if not self.get_intermediate:\n",
        "            raise ValueError(\"TF model must be trained first!\")\n",
        "\n",
        "        return self.get_intermediate(input_list)\n",
        "\n",
        "    def get_sample_prediction(self, sample):\n",
        "        sample = np.array(sample).reshape(\n",
        "            (1, self.ts_obj.n_steps, self.ts_obj.dimensions)\n",
        "        )\n",
        "        output = self.predict_theta_from_input([sample])\n",
        "        samples = []\n",
        "        for mu, sigma in zip(output[0].reshape(-1), output[1].reshape(-1)):\n",
        "            sample = normal(\n",
        "                loc=mu, scale=np.sqrt(sigma), size=1\n",
        "            )  # self.ts_obj.dimensions)\n",
        "            samples.append(sample)\n",
        "        return np.array(samples).reshape((self.ts_obj.n_steps, self.ts_obj.dimensions))\n",
        "\n",
        "\n",
        "def ts_generator(ts_obj, n_steps):\n",
        "    \"\"\"\n",
        "    This is a util generator function for Keras\n",
        "    :param ts_obj: a Dataset child class object that implements the 'next_batch' method\n",
        "    :param n_steps: parameter that specifies the length of the net's input tensor\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    while 1:\n",
        "        batch = ts_obj.next_batch(1, n_steps)\n",
        "        yield batch[0], batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTGTf6DA3kOn",
        "outputId": "4b245b61-38c2-421d-d5ed-30ec8dd31c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf_keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf_keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tTVV6hqt3p_g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ScDEdYzcDBnB"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "q8IiuqecJNw0",
        "outputId": "31206746-f806-4005-ccc3-64c448f22f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-26fa70194d5b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMockTs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# you can change this for multivariate time-series!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiate_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-75fb4bac85fc>\u001b[0m in \u001b[0;36minstantiate_and_fit\u001b[0;34m(self, epochs, verbose, do_fit)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;34m\"\"\"Compile and train model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-75fb4bac85fc>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, verbose, patience)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         self.keras_model.fit(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mts_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-75fb4bac85fc>\u001b[0m in \u001b[0;36mgaussian_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m         return tf.reduce_mean(\n\u001b[1;32m     85\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             + tf.math.truediv(\n\u001b[1;32m     88\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Tried to convert 'x' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ],
      "source": [
        "ts = MockTs(dimensions=2, batch_size=5, n_steps=10)  # you can change this for multivariate time-series!\n",
        "dp_model = DeepAR(ts, epochs=5)\n",
        "dp_model.instantiate_and_fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AOS_RUHbqAZG"
      },
      "outputs": [],
      "source": [
        "batch = ts.__next__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5POD3znksGcP",
        "outputId": "ee3eafe2-6b81-45bc-84ac-67de0e7fbae7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0][0] == batch[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8nJu5EFqxjg",
        "outputId": "92cabd3c-2b71-4b4b-b243-4a2177832658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -6.95564949,  -1.25049468],\n",
              "       [ -6.90532838,  -1.56263508],\n",
              "       [ -6.88388741,  -1.8803695 ],\n",
              "       [ -6.89577021,  -2.19570286],\n",
              "       [ -6.94402492,  -2.50075805],\n",
              "       [ -7.03018103,  -2.78808849],\n",
              "       [ -7.15418673,  -3.05097344],\n",
              "       [ -7.31440941,  -3.28368445],\n",
              "       [ -7.50769913,  -3.48171213],\n",
              "       [ -7.72951261,  -3.64194438],\n",
              "       [ -7.97409277,  -3.76278886],\n",
              "       [ -8.23469672,  -3.8442349 ],\n",
              "       [ -8.50386303,  -3.88785226],\n",
              "       [ -8.77370769,  -3.89672697],\n",
              "       [ -9.03623692,  -3.87533661],\n",
              "       [ -9.28366436,  -3.82937018],\n",
              "       [ -9.50872006,  -3.76549962],\n",
              "       [ -9.70493887,  -3.69111213],\n",
              "       [ -9.86691676,  -3.614014  ],\n",
              "       [ -9.99052487,  -3.54211765],\n",
              "       [-10.07307277,  -3.48312453],\n",
              "       [-10.11341433,  -3.44421632],\n",
              "       [-10.11199214,  -3.4317669 ],\n",
              "       [-10.07081854,  -3.45108654]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yac-xs3q01z",
        "outputId": "5d56d547-1ff2-44d7-b31d-6e7bcc298b7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -6.95564949,  -1.25049468],\n",
              "       [ -6.90532838,  -1.56263508],\n",
              "       [ -6.88388741,  -1.8803695 ],\n",
              "       [ -6.89577021,  -2.19570286],\n",
              "       [ -6.94402492,  -2.50075805],\n",
              "       [ -7.03018103,  -2.78808849],\n",
              "       [ -7.15418673,  -3.05097344],\n",
              "       [ -7.31440941,  -3.28368445],\n",
              "       [ -7.50769913,  -3.48171213],\n",
              "       [ -7.72951261,  -3.64194438],\n",
              "       [ -7.97409277,  -3.76278886],\n",
              "       [ -8.23469672,  -3.8442349 ],\n",
              "       [ -8.50386303,  -3.88785226],\n",
              "       [ -8.77370769,  -3.89672697],\n",
              "       [ -9.03623692,  -3.87533661],\n",
              "       [ -9.28366436,  -3.82937018],\n",
              "       [ -9.50872006,  -3.76549962],\n",
              "       [ -9.70493887,  -3.69111213],\n",
              "       [ -9.86691676,  -3.614014  ],\n",
              "       [ -9.99052487,  -3.54211765],\n",
              "       [-10.07307277,  -3.48312453],\n",
              "       [-10.11341433,  -3.44421632],\n",
              "       [-10.11199214,  -3.4317669 ],\n",
              "       [-10.07081854,  -3.45108654]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dme601MBJR52",
        "outputId": "dede2e00-c62c-4e76-8113-bd966d76d7ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.MockTs at 0x7a7045d8fb10>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from numpy.random import normal\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch = ts.next_batch(1, ts.n_steps)\n",
        "\n",
        "ress = []\n",
        "for i in tqdm.tqdm(range(300)):\n",
        "    ress.append(np.expand_dims(\n",
        "        dp_model.get_sample_prediction(\n",
        "            batch[0]\n",
        "        ), axis=0,\n",
        "    ))\n",
        "\n",
        "res_np = np.concatenate(ress, axis=0)\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "\n",
        "for dim in range(ts.dimensions):\n",
        "    ax = fig.add_subplot(ts.dimensions, 1, dim+1)\n",
        "    res_df = pd.DataFrame(res_np[:, :, 0]).T\n",
        "    tot_res = res_df\n",
        "\n",
        "    ax.plot(batch[1].reshape((ts.n_steps, ts.dimensions))[:, dim], linewidth=6)\n",
        "    tot_res['mu'] = tot_res.apply(lambda x: np.mean(x), axis=1)\n",
        "    tot_res['upper'] = tot_res.apply(lambda x: np.mean(x) + np.std(x), axis=1)\n",
        "    tot_res['lower'] = tot_res.apply(lambda x: np.mean(x) - np.std(x), axis=1)\n",
        "    tot_res['two_upper'] = tot_res.apply(lambda x: np.mean(x) + 2*np.std(x), axis=1)\n",
        "    tot_res['two_lower'] = tot_res.apply(lambda x: np.mean(x) - 2*np.std(x), axis=1)\n",
        "\n",
        "    ax.plot(tot_res.mu, 'bo')\n",
        "    ax.plot(tot_res.mu, linewidth=2)\n",
        "    ax.fill_between(x = tot_res.index, y1=tot_res.lower, y2=tot_res.upper, alpha=0.5)\n",
        "    ax.fill_between(x = tot_res.index, y1=tot_res.two_lower, y2=tot_res.two_upper, alpha=0.5)\n",
        "    fig.suptitle('Prediction uncertainty')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZKN7sNgJYD7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9ciKiZv_ZRW2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "air = pd.read_csv(\"AirPassengers.csv\")['#Passengers'].values\n",
        "source_df = pd.DataFrame({'feature_1': air[:-1], 'target': air[1:]})\n",
        "source_df['category'] = ['1' for i in range(source_df.shape[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l83Y5ea7Aegs",
        "outputId": "175010b4-86b8-4a9e-aa74-9ece794e89f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([112, 118, 132, 129, 121, 135, 148, 148, 136, 119, 104, 118, 115,\n",
              "       126, 141, 135, 125, 149, 170, 170, 158, 133, 114, 140, 145, 150,\n",
              "       178, 163, 172, 178, 199, 199, 184, 162, 146, 166, 171, 180, 193,\n",
              "       181, 183, 218, 230, 242, 209, 191, 172, 194, 196, 196, 236, 235,\n",
              "       229, 243, 264, 272, 237, 211, 180, 201, 204, 188, 235, 227, 234,\n",
              "       264, 302, 293, 259, 229, 203, 229, 242, 233, 267, 269, 270, 315,\n",
              "       364, 347, 312, 274, 237, 278, 284, 277, 317, 313, 318, 374, 413,\n",
              "       405, 355, 306, 271, 306, 315, 301, 356, 348, 355, 422, 465, 467,\n",
              "       404, 347, 305, 336, 340, 318, 362, 348, 363, 435, 491, 505, 404,\n",
              "       359, 310, 337, 360, 342, 406, 396, 420, 472, 548, 559, 463, 407,\n",
              "       362, 405, 417, 391, 419, 461, 472, 535, 622, 606, 508, 461, 390,\n",
              "       432])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rI_yQPxc5qUO",
        "outputId": "029294d6-4c34-4f3b-82c7-6b8f98b0784c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"source_df\",\n  \"rows\": 143,\n  \"fields\": [\n    {\n      \"column\": \"feature_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 104,\n        \"max\": 622,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          229,\n          121,\n          227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 104,\n        \"max\": 622,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          243,\n          135,\n          234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "source_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a1441362-8bc1-48a5-b81e-955935e06fc3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>132</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>129</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>622</td>\n",
              "      <td>606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>606</td>\n",
              "      <td>508</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>508</td>\n",
              "      <td>461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>461</td>\n",
              "      <td>390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>390</td>\n",
              "      <td>432</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1441362-8bc1-48a5-b81e-955935e06fc3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1441362-8bc1-48a5-b81e-955935e06fc3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1441362-8bc1-48a5-b81e-955935e06fc3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f647a2e2-280e-47a6-b57f-a813a76f24eb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f647a2e2-280e-47a6-b57f-a813a76f24eb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f647a2e2-280e-47a6-b57f-a813a76f24eb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     feature_1  target category\n",
              "0          112     118        1\n",
              "1          118     132        1\n",
              "2          132     129        1\n",
              "3          129     121        1\n",
              "4          121     135        1\n",
              "..         ...     ...      ...\n",
              "138        622     606        1\n",
              "139        606     508        1\n",
              "140        508     461        1\n",
              "141        461     390        1\n",
              "142        390     432        1\n",
              "\n",
              "[143 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LzSnM7LBcp-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iQ5ElyppZRcD"
      },
      "outputs": [],
      "source": [
        "# from deepar.deepar.dataset.time_series import TimeSeries\n",
        "# from deepar.model.lstm import DeepAR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ts = TimeSeries(source_df, scaler=MinMaxScaler)\n",
        "# dp_model = DeepAR(ts, epochs=100)\n",
        "# dp_model.instantiate_and_fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "mtXavxnasg8q",
        "outputId": "704d00ee-bb75-433b-ed96-4c32f52c4483"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ae3709c42389>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-1c7c5936fb39>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;34m\"\"\"Iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_one_hot_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1c7c5936fb39>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, n_steps, target_var, verbose, padding_value)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         return (\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mrnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given"
          ]
        }
      ],
      "source": [
        "batch = ts.__next__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMhIfbguZaPI"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from numpy.random import normal\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch = ts.next_batch(1, 20)\n",
        "\n",
        "def get_sample_prediction(sample, prediction_fn):\n",
        "    sample = np.array(sample).reshape(1, 20, 1)\n",
        "    output = prediction_fn([sample])\n",
        "    samples = []\n",
        "    for mu,sigma in zip(output[0].reshape(20), output[1].reshape(20)):\n",
        "        samples.append(normal(loc=mu, scale=np.sqrt(sigma), size=1)[0])\n",
        "    return np.array(samples)\n",
        "\n",
        "ress = []\n",
        "for i in tqdm.tqdm(range(300)):\n",
        "    pred = get_sample_prediction(batch[0], dp_model.predict_theta_from_input)\n",
        "    ress.append(pred)\n",
        "\n",
        "def plot_uncertainty(ress, ground_truth, n_steps=20, figsize=(9, 6),\n",
        "                     prediction_dots=True, title='Prediction on training set'):\n",
        "\n",
        "    res_df = pd.DataFrame(ress).T\n",
        "    tot_res = res_df\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(ground_truth.reshape(n_steps), linewidth=6, label='Original data')\n",
        "    tot_res['mu'] = tot_res.apply(lambda x: np.mean(x), axis=1)\n",
        "    tot_res['upper'] = tot_res.apply(lambda x: np.mean(x) + np.std(x), axis=1)\n",
        "    tot_res['lower'] = tot_res.apply(lambda x: np.mean(x) - np.std(x), axis=1)\n",
        "    tot_res['two_upper'] = tot_res.apply(lambda x: np.mean(x) + 2*np.std(x), axis=1)\n",
        "    tot_res['two_lower'] = tot_res.apply(lambda x: np.mean(x) - 2*np.std(x), axis=1)\n",
        "\n",
        "    plt.plot(tot_res.mu, linewidth=4)\n",
        "    if prediction_dots:\n",
        "        plt.plot(tot_res.mu, 'bo', label='Likelihood mean')\n",
        "    plt.fill_between(x = tot_res.index, y1=tot_res.lower, y2=tot_res.upper, alpha=0.5)\n",
        "    plt.fill_between(x = tot_res.index, y1=tot_res.two_lower, y2=tot_res.two_upper, alpha=0.5)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "\n",
        "plot_uncertainty(ress, batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOiXPWIrZZZ1"
      },
      "outputs": [],
      "source": [
        "# Evaluate fit on training set\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "source_df['feature_1'] = source_df.feature_1.astype('float')\n",
        "X_batches = source_df.feature_1.values[:-3].reshape(-1, 20)\n",
        "y = source_df.target.values[:-3].reshape(-1, 20)\n",
        "\n",
        "predictions = []\n",
        "for batch in X_batches:\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_batch = scaler.fit_transform(batch.reshape(20, 1))\n",
        "    ress = []\n",
        "    for i in tqdm.tqdm(range(300)):\n",
        "        unscaled_prediction = get_sample_prediction(scaled_batch, dp_model.predict_theta_from_input)\n",
        "        ress.append(scaler.inverse_transform([unscaled_prediction])[0])\n",
        "    predictions.append(ress)\n",
        "\n",
        "# Concatenate batches and plot the whole time series\n",
        "prediction_concat = np.concatenate(predictions, axis=1, )\n",
        "ground_truth = np.concatenate(y, axis=0)\n",
        "plot_uncertainty(ress = prediction_concat, ground_truth=ground_truth,\n",
        "                 n_steps=140, figsize=(15, 9), prediction_dots=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM51ewvhZthv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPGtFfO+wqb6DajvLiXcxK/",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
