{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQyOudRcMXe",
        "outputId": "780e9c51-a966-4e8b-c3a1-247f5c380fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepar'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 182 (delta 49), reused 58 (delta 31), pack-reused 89 (from 1)\u001b[K\n",
            "Receiving objects: 100% (182/182), 97.81 KiB | 1.66 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Olyco/deepar.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-BkzG8f1oIG",
        "outputId": "3467c5e8-280d-45df-bbc7-0df81b06d049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 6)) (8.3.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from -r deepar/requirements.txt (line 7)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r deepar/requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r deepar/requirements.txt (line 4)) (0.37.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r deepar/requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r deepar/requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r deepar/requirements.txt (line 6)) (1.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->-r deepar/requirements.txt (line 7)) (0.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r deepar/requirements.txt (line 4)) (0.45.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r deepar/requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r deepar/requirements.txt (line 4)) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->-r deepar/requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->-r deepar/requirements.txt (line 7)) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->-r deepar/requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r deepar/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: tkan in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: keras<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tkan) (3.8.0)\n",
            "Requirement already satisfied: keras_efficient_kan<0.2.0,>=0.1.9 in /usr/local/lib/python3.11/dist-packages (from tkan) (0.1.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras<4.0.0,>=3.0.0->tkan) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras<4.0.0,>=3.0.0->tkan) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras<4.0.0,>=3.0.0->tkan) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r deepar/requirements.txt\n",
        "!pip install tkan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsNRwFh_DYLX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTGTf6DA3kOn",
        "outputId": "25a1d4e1-38e2-45da-cc3f-82511adfc871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tf_keras) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18->tf_keras) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf_keras) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf_keras) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf_keras) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf_keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf_keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EuPhEPuJ6t1"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "TojYcp6RCzMC"
      },
      "outputs": [],
      "source": [
        "#@title датасет\n",
        "from abc import ABC\n",
        "\n",
        "\n",
        "class Dataset(ABC):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def next_batch(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(\"deepar\")\n",
        "\n",
        "\n",
        "class MockTs(Dataset):\n",
        "    \"\"\"\n",
        "    This class generates 'mock' time series data of the form (y = t * np.sin(t/6) / 3 +np.sin(t*2))\n",
        "    Created mainly for showcase/testing purpose\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dimensions=1, t_min=0, t_max=30, resolution=0.1, batch_size=1, n_steps=10\n",
        "    ):\n",
        "        self.dimensions = dimensions\n",
        "        self.t_min = t_min\n",
        "        self.t_max = t_max\n",
        "        self.resolution = resolution\n",
        "        self.data = True\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    @staticmethod\n",
        "    def _time_series(t):\n",
        "        return t * np.sin(t / 6) / 3 + np.sin(t * 2)\n",
        "\n",
        "    def next_batch(self, batch_size, n_steps):\n",
        "        \"\"\"\n",
        "        Generate next batch (x, y), generate y by lagging x (1 step)\n",
        "        \"\"\"\n",
        "        Y = []\n",
        "        for dim in range(self.dimensions):\n",
        "            t0 = np.random.rand(batch_size, 1) * (\n",
        "                self.t_max - self.t_min - n_steps * self.resolution\n",
        "            )\n",
        "            Ts = t0 + np.arange(0.0, n_steps + 1) * self.resolution\n",
        "            ys = self._time_series(Ts)\n",
        "            Y.append(ys[:, :-1].reshape(-1, n_steps, 1))\n",
        "        return np.concatenate(Y, axis=2), np.concatenate(Y, axis=2)\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Iterator.\"\"\"\n",
        "        return self.next_batch(n_steps=self.n_steps, batch_size=self.batch_size)\n",
        "\n",
        "    @property\n",
        "    def mock_ts(self):\n",
        "        \"\"\"\n",
        "        Return the data used for training (ranging from self.t_min and self.t_max, with resolution self.resolution)\n",
        "        :return: a Numpy array\n",
        "        \"\"\"\n",
        "        t_list = [self.t_min]\n",
        "        results = [self._time_series(t_list[0])]\n",
        "        while t_list[-1] < self.t_max:\n",
        "            t_list.append(t_list[-1] + self.resolution)\n",
        "            results.append(self._time_series(t_list[-1]))\n",
        "        return results\n",
        "\n",
        "    def generate_test_data(self, n_steps):\n",
        "        \"\"\"\n",
        "        Generate test data outside of the training set (t > self.t_max)\n",
        "        :param n_steps:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        t_list = [self.t_max + self.resolution]\n",
        "        results = [self._time_series(t_list[0])]\n",
        "        for i in range(1, n_steps):\n",
        "            t_list.append(t_list[-1] + self.resolution)\n",
        "            results.append(self._time_series(t_list[-1]))\n",
        "        return results\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "\n",
        "class TimeSeries(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pandas_df,\n",
        "        one_hot_root_list=None,\n",
        "        grouping_variable=\"category\",\n",
        "        scaler=None,\n",
        "        n_steps=1,\n",
        "        batch_size=10,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.data = pandas_df\n",
        "        self.one_hot_root_list = one_hot_root_list\n",
        "        self.grouping_variable = grouping_variable\n",
        "        if self.data is None:\n",
        "            raise ValueError(\"Must provide a Pandas df to instantiate this class\")\n",
        "        self.scaler = scaler\n",
        "        self.batch_size = batch_size\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Iterator.\"\"\"\n",
        "        return self.next_batch(n_steps=self.n_steps, batch_size=self.batch_size)\n",
        "\n",
        "    def _one_hot_padding(self, pandas_df, padding_df):\n",
        "        \"\"\"\n",
        "        Util padding function\n",
        "        :param padding_df:\n",
        "        :param one_hot_root_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for one_hot_root in self.one_hot_root_list:\n",
        "            one_hot_columns = [\n",
        "                i\n",
        "                for i in pandas_df.columns  # select columns equal to 1\n",
        "                if i.startswith(one_hot_root) and pandas_df[i].values[0] == 1\n",
        "            ]\n",
        "            for col in one_hot_columns:\n",
        "                padding_df[col] = 1\n",
        "        return padding_df\n",
        "\n",
        "    def _pad_ts(self, pandas_df, desired_len, padding_val=0):\n",
        "        \"\"\"\n",
        "        Add padding int to the time series\n",
        "        :param pandas_df:\n",
        "        :param desired_len: (int)\n",
        "        :param padding_val: (int)\n",
        "        :return: X (feature_space), y\n",
        "        \"\"\"\n",
        "        pad_length = desired_len - pandas_df.shape[0]\n",
        "        padding_df = pd.concat(\n",
        "            [\n",
        "                pd.DataFrame(\n",
        "                    {col: padding_val for col in pandas_df.columns},\n",
        "                    index=[i for i in range(pad_length)],\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if self.one_hot_root_list:\n",
        "            padding_df = self._one_hot_padding(pandas_df, padding_df)\n",
        "\n",
        "        return pd.concat([padding_df, pandas_df]).reset_index(drop=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def _sample_ts(pandas_df, desired_len):\n",
        "        \"\"\"\n",
        "\n",
        "        :param pandas_df: input pandas df with 'target' columns e features\n",
        "        :param desired_len: desired sample length (number of rows)\n",
        "        :param padding_val: default is 0\n",
        "        :param initial_obs: how many observations to skip at the beginning\n",
        "        :return: a pandas df (sample)\n",
        "        \"\"\"\n",
        "        if pandas_df.shape[0] < desired_len:\n",
        "            raise ValueError(\"Desired sample length is greater than df row len\")\n",
        "        if pandas_df.shape[0] == desired_len:\n",
        "            return pandas_df\n",
        "\n",
        "        start_index = np.random.choice(\n",
        "            [i for i in range(0, pandas_df.shape[0] - desired_len + 1)]\n",
        "        )\n",
        "        return pandas_df.iloc[\n",
        "            start_index : start_index + desired_len,\n",
        "        ]\n",
        "\n",
        "    def next_batch(\n",
        "        self, batch_size, n_steps, target_var=\"target\", verbose=False, padding_value=0\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param batch_size: how many time series to be sampled in this batch (int)\n",
        "        :param n_steps: how many RNN cells (int)\n",
        "        :param target_var: (str)\n",
        "        :param verbose: (boolean)\n",
        "        :param padding_value: (float)\n",
        "        :return: X (feature space), y\n",
        "        \"\"\"\n",
        "\n",
        "        # Select n_batch time series\n",
        "        groups_list = self.data[self.grouping_variable].unique()\n",
        "        np.random.shuffle(groups_list)\n",
        "        selected_groups = groups_list[:batch_size]\n",
        "        input_data = self.data[\n",
        "            self.data[self.grouping_variable].isin(set(selected_groups))\n",
        "        ]\n",
        "\n",
        "        # Initial padding for each selected time series to reach n_steps\n",
        "        sampled = []\n",
        "        for cat, cat_data in input_data.groupby(self.grouping_variable):\n",
        "            if cat_data.shape[0] < n_steps:\n",
        "                sampled_cat_data = self._pad_ts(\n",
        "                    pandas_df=cat_data, desired_len=n_steps, padding_val=padding_value\n",
        "                )\n",
        "            else:\n",
        "                sampled_cat_data = self._sample_ts(\n",
        "                    pandas_df=cat_data, desired_len=n_steps\n",
        "                )\n",
        "            sampled.append(sampled_cat_data)\n",
        "            if verbose:\n",
        "                logger.debug(\"Sampled data for {}\".format(cat))\n",
        "                logger.debug(sampled_cat_data)\n",
        "        rnn_output = (\n",
        "            pd.concat(sampled)\n",
        "            .drop(columns=self.grouping_variable)\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "\n",
        "        if self.scaler:\n",
        "            batch_scaler = self.scaler()\n",
        "            n_rows = rnn_output.shape[0]\n",
        "            # Scaling will have to be extended to handle multiple variables!\n",
        "            rnn_output[\"feature_1\"] = rnn_output.feature_1.astype(\"float\")\n",
        "            rnn_output[target_var] = rnn_output[target_var].astype(\"float\")\n",
        "\n",
        "            rnn_output[\"feature_1\"] = batch_scaler.fit_transform(\n",
        "                rnn_output.feature_1.values.reshape(n_rows, 1)\n",
        "            ).reshape(n_rows)\n",
        "            rnn_output[target_var] = batch_scaler.fit_transform(\n",
        "                rnn_output[target_var].values.reshape(n_rows, 1)\n",
        "            ).reshape(n_rows)\n",
        "\n",
        "        return (\n",
        "            rnn_output.drop(target_var, 1).values.reshape(batch_size, n_steps, -1),\n",
        "            rnn_output[target_var].values.reshape(batch_size, n_steps, 1),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title loss\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "# from keras.layers import Layer, Lambda\n",
        "\n",
        "import keras\n",
        "from keras.losses import Loss\n",
        "\n",
        "# class GaussianLikelihood(Loss):\n",
        "#     def __init__(self, sigma, **kwargs):\n",
        "#         super(self).__init__(**kwargs)\n",
        "#         self.sigma = sigma\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         y_true, y_pred = inputs\n",
        "#         loss = (\n",
        "#             tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "#             + tf.math.log(self.sigma)\n",
        "#             + tf.math.truediv(\n",
        "#                 tf.math.square(y_true - y_pred),\n",
        "#                 2 * tf.math.square(self.sigma)\n",
        "#             )\n",
        "#         )\n",
        "#         return tf.reduce_mean(loss)\n",
        "\n",
        "# class GaussianLikelihood(Layer):\n",
        "#     def __init__(self, sigma, **kwargs):\n",
        "#         super(GaussianLikelihood, self).__init__(**kwargs)\n",
        "#         self.sigma = sigma\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         y_true, y_pred = inputs\n",
        "#         loss = (\n",
        "#             tf.math.log(tf.math.sqrt(2 * math.pi))\n",
        "#             + tf.math.log(self.sigma)\n",
        "#             + tf.math.truediv(\n",
        "#                 tf.math.square(y_true - y_pred),\n",
        "#                 2 * tf.math.square(self.sigma)\n",
        "#             )\n",
        "#         )\n",
        "#         return tf.reduce_mean(loss)\n",
        "\n",
        "from keras import ops\n",
        "\n",
        "def gaussian_likelihood(sigma):\n",
        "    \"\"\"Likelihood as per the paper.\"\"\"\n",
        "\n",
        "    def gaussian_loss(y_true, y_pred):\n",
        "        \"\"\"Updated from paper.\n",
        "\n",
        "        See DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks.\n",
        "        \"\"\"\n",
        "        print(type(sigma))\n",
        "        return ops.mean(\n",
        "            ops.log(ops.sqrt(2 * math.pi))\n",
        "            + ops.log(sigma)\n",
        "            +  ops.divide(\n",
        "                ops.square(y_true - y_pred), 2 * ops.square(sigma)\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return gaussian_loss"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OcBoXfd6WMt_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VQmyLmmfC9ou"
      },
      "outputs": [],
      "source": [
        "#@title модель\n",
        "from abc import ABC\n",
        "\n",
        "\n",
        "class NNModel(ABC):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def net_structure(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def instantiate_and_fit(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "# from keras import backend as K\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.layers import Layer, Dense, Input, LSTM\n",
        "\n",
        "import math\n",
        "from functools import partial\n",
        "import logging\n",
        "from typing import Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import normal\n",
        "\n",
        "from keras import Model\n",
        "from tensorflow.python.keras import backend as K\n",
        "from keras import callbacks\n",
        "\n",
        "\n",
        "class GaussianLayer(Layer):\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        \"\"\"Init.\"\"\"\n",
        "        self.output_dim = output_dim\n",
        "        self.kernel_1, self.kernel_2, self.bias_1, self.bias_2 = [], [], [], []\n",
        "        super(GaussianLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Build the weights and biases.\"\"\"\n",
        "        n_weight_rows = input_shape[2]\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            name=\"kernel_1\",\n",
        "            shape=(n_weight_rows, self.output_dim),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.kernel_2 = self.add_weight(\n",
        "            name=\"kernel_2\",\n",
        "            shape=(n_weight_rows, self.output_dim),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.bias_1 = self.add_weight(\n",
        "            name=\"bias_1\",\n",
        "            shape=(self.output_dim,),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.bias_2 = self.add_weight(\n",
        "            name=\"bias_2\",\n",
        "            shape=(self.output_dim,),\n",
        "            initializer=glorot_normal(),\n",
        "            trainable=True,\n",
        "        )\n",
        "        super(GaussianLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Do the layer computation.\"\"\"\n",
        "        print(type(x))\n",
        "        output_mu = K.dot(x, self.kernel_1) + self.bias_1\n",
        "        output_sig = K.dot(x, self.kernel_2) + self.bias_2\n",
        "        output_sig_pos = K.log(1 + K.exp(output_sig)) + 1e-06\n",
        "        return [output_mu, output_sig_pos]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\"Calculate the output dimensions.\n",
        "\n",
        "        The assumption here is that the output ts is always one-dimensional;\n",
        "        \"\"\"\n",
        "        return [(input_shape[0], self.output_dim), (input_shape[0], self.output_dim)]\n",
        "\n",
        "\n",
        "# from deepar.model.loss import gaussian_likelihood\n",
        "# from deepar.model import NNModel\n",
        "# from deepar.model.layers import GaussianLayer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class DeepAR(NNModel):\n",
        "    def __init__(\n",
        "        self,\n",
        "        ts_obj,\n",
        "        steps_per_epoch=50,\n",
        "        epochs=100,\n",
        "        loss=gaussian_likelihood,\n",
        "        optimizer=\"adam\",\n",
        "        with_custom_nn_structure=None,\n",
        "    ):\n",
        "        \"\"\"Init.\"\"\"\n",
        "\n",
        "        self.ts_obj = ts_obj\n",
        "        self.inputs, self.z_sample = None, None\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.epochs = epochs\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.keras_model = None\n",
        "        if with_custom_nn_structure:\n",
        "            self.nn_structure = with_custom_nn_structure\n",
        "        else:\n",
        "            self.nn_structure = partial(\n",
        "                DeepAR.basic_structure,\n",
        "                n_steps=self.ts_obj.n_steps,\n",
        "                dimensions=self.ts_obj.dimensions,\n",
        "            )\n",
        "        # self.loss = GaussianLikelihood(self.nn_structure())\n",
        "        self._output_layer_name = \"main_output\"\n",
        "        self.get_intermediate = None\n",
        "\n",
        "    @staticmethod\n",
        "    def basic_structure(n_steps=20, dimensions=1):\n",
        "        \"\"\"\n",
        "        This is the method that needs to be patched when changing NN structure\n",
        "        :return: inputs_shape (tuple), inputs (Tensor), [loc, scale] (a list of theta parameters\n",
        "        of the target likelihood).\n",
        "\n",
        "        Please note that I've made up scaling rules of the hidden layer dimensions.\n",
        "        \"\"\"\n",
        "        input_shape = (n_steps, dimensions)\n",
        "        inputs = Input(shape=input_shape)\n",
        "        x = LSTM(\n",
        "            int(4 * (1 + math.pow(math.log(dimensions), 4))),\n",
        "            return_sequences=True,\n",
        "            dropout=0.1,\n",
        "        )(inputs)\n",
        "        x = Dense(int(4 * (1 + math.log(dimensions))), activation=\"relu\")(x)\n",
        "        loc, scale = GaussianLayer(dimensions, name=\"main_output\")(x)\n",
        "        return input_shape, inputs, [loc, scale]\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        epochs: Optional[int] = None,\n",
        "        verbose: Union[str, int] = \"auto\",\n",
        "        patience: int = 10,\n",
        "    ):\n",
        "        \"\"\"Fit model.\n",
        "\n",
        "        This is called from instantiate and fit().\n",
        "\n",
        "        Args:\n",
        "            epochs (Optional[int]): number of epochs to train. If nothing\n",
        "                defined, take self.epochs. Please the early stopping (patience).\n",
        "            verbose (Union[str, int]): passed to keras.fit(). Can be\n",
        "                \"auto\", 0, or 1.\n",
        "            patience (int): Number of epochs without without improvement to stop.\n",
        "        \"\"\"\n",
        "        if not epochs:\n",
        "            epochs = self.epochs\n",
        "        callback = callbacks.EarlyStopping(monitor=\"loss\", patience=patience)\n",
        "        self.keras_model.fit(\n",
        "            ts_generator(self.ts_obj, self.ts_obj.n_steps),\n",
        "            steps_per_epoch=self.steps_per_epoch,\n",
        "            epochs=epochs,\n",
        "            verbose=verbose,\n",
        "            callbacks=[callback],\n",
        "        )\n",
        "        if verbose:\n",
        "            logger.debug(\"Model was successfully trained\")\n",
        "        self.get_intermediate = K.function(\n",
        "            inputs=[self.keras_model.input],\n",
        "            outputs=self.keras_model.get_layer(self._output_layer_name).output,\n",
        "        )\n",
        "\n",
        "    def build_model(self, n_steps=20, dimensions=1):\n",
        "        input_shape = (n_steps, dimensions)\n",
        "        # input_shape, inputs, theta = self.nn_structure()\n",
        "        # print(input_shape, inputs, theta)\n",
        "        inputs = Input(shape=input_shape)\n",
        "        x = LSTM(\n",
        "            int(4 * (1 + math.pow(math.log(dimensions), 4))),\n",
        "            return_sequences=True,\n",
        "            dropout=0.1,\n",
        "        )(inputs)\n",
        "        x = Dense(int(4 * (1 + math.log(dimensions))), activation=\"relu\")(x)\n",
        "        loc, scale = GaussianLayer(dimensions, name=\"main_output\")(x)\n",
        "        model = keras.Model(inputs=inputs, outputs=loc)\n",
        "        # model = Model(inputs, theta[0])\n",
        "        model.compile(loss=self.loss(scale), optimizer=self.optimizer)\n",
        "        self.keras_model = model\n",
        "\n",
        "    def instantiate_and_fit(\n",
        "        self,\n",
        "        epochs: Optional[int] = None,\n",
        "        verbose: Union[str, int] = \"auto\",\n",
        "        do_fit: bool = True,\n",
        "        n_steps=20,\n",
        "    ):\n",
        "        \"\"\"Compile and train model.\"\"\"\n",
        "        self.build_model(n_steps=n_steps)\n",
        "        self.fit(verbose=verbose, epochs=epochs)\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.keras_model\n",
        "\n",
        "    def predict_theta_from_input(self, input_list):\n",
        "        \"\"\"\n",
        "        This function takes an input of size equal to the n_steps specified in 'Input' when building the\n",
        "        network\n",
        "        :param input_list:\n",
        "        :return: [[]], a list of list. E.g. when using Gaussian layer this returns a list of two list,\n",
        "        corresponding to [[mu_values], [sigma_values]]\n",
        "        \"\"\"\n",
        "        if not self.get_intermediate:\n",
        "            raise ValueError(\"TF model must be trained first!\")\n",
        "\n",
        "        return self.get_intermediate(input_list)\n",
        "\n",
        "    def get_sample_prediction(self, sample):\n",
        "        sample = np.array(sample).reshape(\n",
        "            (1, self.ts_obj.n_steps, self.ts_obj.dimensions)\n",
        "        )\n",
        "        output = self.predict_theta_from_input([sample])\n",
        "        samples = []\n",
        "        for mu, sigma in zip(output[0].reshape(-1), output[1].reshape(-1)):\n",
        "            sample = normal(\n",
        "                loc=mu, scale=np.sqrt(sigma), size=1\n",
        "            )  # self.ts_obj.dimensions)\n",
        "            samples.append(sample)\n",
        "        return np.array(samples).reshape((self.ts_obj.n_steps, self.ts_obj.dimensions))\n",
        "\n",
        "\n",
        "def ts_generator(ts_obj, n_steps):\n",
        "    \"\"\"\n",
        "    This is a util generator function for Keras\n",
        "    :param ts_obj: a Dataset child class object that implements the 'next_batch' method\n",
        "    :param n_steps: parameter that specifies the length of the net's input tensor\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    while 1:\n",
        "        batch = ts_obj.next_batch(1, n_steps)\n",
        "        yield batch[0], batch[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tTVV6hqt3p_g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScDEdYzcDBnB"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# from tensorflow.python.framework.ops import disable_eager_execution\n",
        "# disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "q8IiuqecJNw0",
        "outputId": "edd6c6de-a38a-4eb9-f97b-c936252ce700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "<class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "<class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
            "<class 'keras.src.backend.common.keras_tensor.KerasTensor'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b2df89b8509f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMockTs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# you can change this for multivariate time-series!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstantiate_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-bd41298786e2>\u001b[0m in \u001b[0;36minstantiate_and_fit\u001b[0;34m(self, epochs, verbose, do_fit, n_steps)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;34m\"\"\"Compile and train model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-bd41298786e2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, verbose, patience)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         self.keras_model.fit(\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0mts_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mts_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ],
      "source": [
        "ts = MockTs(dimensions=1, batch_size=5, n_steps=10)  # you can change this for multivariate time-series!\n",
        "dp_model = DeepAR(ts, epochs=2)\n",
        "dp_model.instantiate_and_fit(n_steps=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOS_RUHbqAZG"
      },
      "outputs": [],
      "source": [
        "batch = ts.__next__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5POD3znksGcP",
        "outputId": "ee3eafe2-6b81-45bc-84ac-67de0e7fbae7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True],\n",
              "       [ True,  True]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0][0] == batch[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8nJu5EFqxjg",
        "outputId": "92cabd3c-2b71-4b4b-b243-4a2177832658"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -6.95564949,  -1.25049468],\n",
              "       [ -6.90532838,  -1.56263508],\n",
              "       [ -6.88388741,  -1.8803695 ],\n",
              "       [ -6.89577021,  -2.19570286],\n",
              "       [ -6.94402492,  -2.50075805],\n",
              "       [ -7.03018103,  -2.78808849],\n",
              "       [ -7.15418673,  -3.05097344],\n",
              "       [ -7.31440941,  -3.28368445],\n",
              "       [ -7.50769913,  -3.48171213],\n",
              "       [ -7.72951261,  -3.64194438],\n",
              "       [ -7.97409277,  -3.76278886],\n",
              "       [ -8.23469672,  -3.8442349 ],\n",
              "       [ -8.50386303,  -3.88785226],\n",
              "       [ -8.77370769,  -3.89672697],\n",
              "       [ -9.03623692,  -3.87533661],\n",
              "       [ -9.28366436,  -3.82937018],\n",
              "       [ -9.50872006,  -3.76549962],\n",
              "       [ -9.70493887,  -3.69111213],\n",
              "       [ -9.86691676,  -3.614014  ],\n",
              "       [ -9.99052487,  -3.54211765],\n",
              "       [-10.07307277,  -3.48312453],\n",
              "       [-10.11341433,  -3.44421632],\n",
              "       [-10.11199214,  -3.4317669 ],\n",
              "       [-10.07081854,  -3.45108654]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yac-xs3q01z",
        "outputId": "5d56d547-1ff2-44d7-b31d-6e7bcc298b7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ -6.95564949,  -1.25049468],\n",
              "       [ -6.90532838,  -1.56263508],\n",
              "       [ -6.88388741,  -1.8803695 ],\n",
              "       [ -6.89577021,  -2.19570286],\n",
              "       [ -6.94402492,  -2.50075805],\n",
              "       [ -7.03018103,  -2.78808849],\n",
              "       [ -7.15418673,  -3.05097344],\n",
              "       [ -7.31440941,  -3.28368445],\n",
              "       [ -7.50769913,  -3.48171213],\n",
              "       [ -7.72951261,  -3.64194438],\n",
              "       [ -7.97409277,  -3.76278886],\n",
              "       [ -8.23469672,  -3.8442349 ],\n",
              "       [ -8.50386303,  -3.88785226],\n",
              "       [ -8.77370769,  -3.89672697],\n",
              "       [ -9.03623692,  -3.87533661],\n",
              "       [ -9.28366436,  -3.82937018],\n",
              "       [ -9.50872006,  -3.76549962],\n",
              "       [ -9.70493887,  -3.69111213],\n",
              "       [ -9.86691676,  -3.614014  ],\n",
              "       [ -9.99052487,  -3.54211765],\n",
              "       [-10.07307277,  -3.48312453],\n",
              "       [-10.11341433,  -3.44421632],\n",
              "       [-10.11199214,  -3.4317669 ],\n",
              "       [-10.07081854,  -3.45108654]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dme601MBJR52",
        "outputId": "dede2e00-c62c-4e76-8113-bd966d76d7ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.MockTs at 0x7a7045d8fb10>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from numpy.random import normal\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch = ts.next_batch(1, ts.n_steps)\n",
        "\n",
        "ress = []\n",
        "for i in tqdm.tqdm(range(300)):\n",
        "    ress.append(np.expand_dims(\n",
        "        dp_model.get_sample_prediction(\n",
        "            batch[0]\n",
        "        ), axis=0,\n",
        "    ))\n",
        "\n",
        "res_np = np.concatenate(ress, axis=0)\n",
        "fig = plt.figure(figsize=(12, 10))\n",
        "\n",
        "for dim in range(ts.dimensions):\n",
        "    ax = fig.add_subplot(ts.dimensions, 1, dim+1)\n",
        "    res_df = pd.DataFrame(res_np[:, :, 0]).T\n",
        "    tot_res = res_df\n",
        "\n",
        "    ax.plot(batch[1].reshape((ts.n_steps, ts.dimensions))[:, dim], linewidth=6)\n",
        "    tot_res['mu'] = tot_res.apply(lambda x: np.mean(x), axis=1)\n",
        "    tot_res['upper'] = tot_res.apply(lambda x: np.mean(x) + np.std(x), axis=1)\n",
        "    tot_res['lower'] = tot_res.apply(lambda x: np.mean(x) - np.std(x), axis=1)\n",
        "    tot_res['two_upper'] = tot_res.apply(lambda x: np.mean(x) + 2*np.std(x), axis=1)\n",
        "    tot_res['two_lower'] = tot_res.apply(lambda x: np.mean(x) - 2*np.std(x), axis=1)\n",
        "\n",
        "    ax.plot(tot_res.mu, 'bo')\n",
        "    ax.plot(tot_res.mu, linewidth=2)\n",
        "    ax.fill_between(x = tot_res.index, y1=tot_res.lower, y2=tot_res.upper, alpha=0.5)\n",
        "    ax.fill_between(x = tot_res.index, y1=tot_res.two_lower, y2=tot_res.two_upper, alpha=0.5)\n",
        "    fig.suptitle('Prediction uncertainty')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZKN7sNgJYD7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ciKiZv_ZRW2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "air = pd.read_csv(\"AirPassengers.csv\")['#Passengers'].values\n",
        "source_df = pd.DataFrame({'feature_1': air[:-1], 'target': air[1:]})\n",
        "source_df['category'] = ['1' for i in range(source_df.shape[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l83Y5ea7Aegs",
        "outputId": "175010b4-86b8-4a9e-aa74-9ece794e89f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([112, 118, 132, 129, 121, 135, 148, 148, 136, 119, 104, 118, 115,\n",
              "       126, 141, 135, 125, 149, 170, 170, 158, 133, 114, 140, 145, 150,\n",
              "       178, 163, 172, 178, 199, 199, 184, 162, 146, 166, 171, 180, 193,\n",
              "       181, 183, 218, 230, 242, 209, 191, 172, 194, 196, 196, 236, 235,\n",
              "       229, 243, 264, 272, 237, 211, 180, 201, 204, 188, 235, 227, 234,\n",
              "       264, 302, 293, 259, 229, 203, 229, 242, 233, 267, 269, 270, 315,\n",
              "       364, 347, 312, 274, 237, 278, 284, 277, 317, 313, 318, 374, 413,\n",
              "       405, 355, 306, 271, 306, 315, 301, 356, 348, 355, 422, 465, 467,\n",
              "       404, 347, 305, 336, 340, 318, 362, 348, 363, 435, 491, 505, 404,\n",
              "       359, 310, 337, 360, 342, 406, 396, 420, 472, 548, 559, 463, 407,\n",
              "       362, 405, 417, 391, 419, 461, 472, 535, 622, 606, 508, 461, 390,\n",
              "       432])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "air"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rI_yQPxc5qUO",
        "outputId": "029294d6-4c34-4f3b-82c7-6b8f98b0784c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"source_df\",\n  \"rows\": 143,\n  \"fields\": [\n    {\n      \"column\": \"feature_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 104,\n        \"max\": 622,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          229,\n          121,\n          227\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 104,\n        \"max\": 622,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          243,\n          135,\n          234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "source_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a1441362-8bc1-48a5-b81e-955935e06fc3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>112</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>132</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>129</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>622</td>\n",
              "      <td>606</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>606</td>\n",
              "      <td>508</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>508</td>\n",
              "      <td>461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>461</td>\n",
              "      <td>390</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>390</td>\n",
              "      <td>432</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1441362-8bc1-48a5-b81e-955935e06fc3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1441362-8bc1-48a5-b81e-955935e06fc3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1441362-8bc1-48a5-b81e-955935e06fc3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f647a2e2-280e-47a6-b57f-a813a76f24eb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f647a2e2-280e-47a6-b57f-a813a76f24eb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f647a2e2-280e-47a6-b57f-a813a76f24eb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     feature_1  target category\n",
              "0          112     118        1\n",
              "1          118     132        1\n",
              "2          132     129        1\n",
              "3          129     121        1\n",
              "4          121     135        1\n",
              "..         ...     ...      ...\n",
              "138        622     606        1\n",
              "139        606     508        1\n",
              "140        508     461        1\n",
              "141        461     390        1\n",
              "142        390     432        1\n",
              "\n",
              "[143 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "source_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LzSnM7LBcp-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ5ElyppZRcD"
      },
      "outputs": [],
      "source": [
        "# from deepar.deepar.dataset.time_series import TimeSeries\n",
        "# from deepar.model.lstm import DeepAR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ts = TimeSeries(source_df, scaler=MinMaxScaler)\n",
        "# dp_model = DeepAR(ts, epochs=100)\n",
        "# dp_model.instantiate_and_fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "mtXavxnasg8q",
        "outputId": "704d00ee-bb75-433b-ed96-4c32f52c4483"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ae3709c42389>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-1c7c5936fb39>\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;34m\"\"\"Iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_one_hot_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1c7c5936fb39>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, n_steps, target_var, verbose, padding_value)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         return (\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mrnn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mrnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given"
          ]
        }
      ],
      "source": [
        "batch = ts.__next__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMhIfbguZaPI"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from numpy.random import normal\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "batch = ts.next_batch(1, 20)\n",
        "\n",
        "def get_sample_prediction(sample, prediction_fn):\n",
        "    sample = np.array(sample).reshape(1, 20, 1)\n",
        "    output = prediction_fn([sample])\n",
        "    samples = []\n",
        "    for mu,sigma in zip(output[0].reshape(20), output[1].reshape(20)):\n",
        "        samples.append(normal(loc=mu, scale=np.sqrt(sigma), size=1)[0])\n",
        "    return np.array(samples)\n",
        "\n",
        "ress = []\n",
        "for i in tqdm.tqdm(range(300)):\n",
        "    pred = get_sample_prediction(batch[0], dp_model.predict_theta_from_input)\n",
        "    ress.append(pred)\n",
        "\n",
        "def plot_uncertainty(ress, ground_truth, n_steps=20, figsize=(9, 6),\n",
        "                     prediction_dots=True, title='Prediction on training set'):\n",
        "\n",
        "    res_df = pd.DataFrame(ress).T\n",
        "    tot_res = res_df\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(ground_truth.reshape(n_steps), linewidth=6, label='Original data')\n",
        "    tot_res['mu'] = tot_res.apply(lambda x: np.mean(x), axis=1)\n",
        "    tot_res['upper'] = tot_res.apply(lambda x: np.mean(x) + np.std(x), axis=1)\n",
        "    tot_res['lower'] = tot_res.apply(lambda x: np.mean(x) - np.std(x), axis=1)\n",
        "    tot_res['two_upper'] = tot_res.apply(lambda x: np.mean(x) + 2*np.std(x), axis=1)\n",
        "    tot_res['two_lower'] = tot_res.apply(lambda x: np.mean(x) - 2*np.std(x), axis=1)\n",
        "\n",
        "    plt.plot(tot_res.mu, linewidth=4)\n",
        "    if prediction_dots:\n",
        "        plt.plot(tot_res.mu, 'bo', label='Likelihood mean')\n",
        "    plt.fill_between(x = tot_res.index, y1=tot_res.lower, y2=tot_res.upper, alpha=0.5)\n",
        "    plt.fill_between(x = tot_res.index, y1=tot_res.two_lower, y2=tot_res.two_upper, alpha=0.5)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "\n",
        "plot_uncertainty(ress, batch[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOiXPWIrZZZ1"
      },
      "outputs": [],
      "source": [
        "# Evaluate fit on training set\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "source_df['feature_1'] = source_df.feature_1.astype('float')\n",
        "X_batches = source_df.feature_1.values[:-3].reshape(-1, 20)\n",
        "y = source_df.target.values[:-3].reshape(-1, 20)\n",
        "\n",
        "predictions = []\n",
        "for batch in X_batches:\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_batch = scaler.fit_transform(batch.reshape(20, 1))\n",
        "    ress = []\n",
        "    for i in tqdm.tqdm(range(300)):\n",
        "        unscaled_prediction = get_sample_prediction(scaled_batch, dp_model.predict_theta_from_input)\n",
        "        ress.append(scaler.inverse_transform([unscaled_prediction])[0])\n",
        "    predictions.append(ress)\n",
        "\n",
        "# Concatenate batches and plot the whole time series\n",
        "prediction_concat = np.concatenate(predictions, axis=1, )\n",
        "ground_truth = np.concatenate(y, axis=0)\n",
        "plot_uncertainty(ress = prediction_concat, ground_truth=ground_truth,\n",
        "                 n_steps=140, figsize=(15, 9), prediction_dots=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM51ewvhZthv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# С нуля"
      ],
      "metadata": {
        "id": "vf7E_T_LO7uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from keras import ops, layers, Model, optimizers\n",
        "from keras.initializers import glorot_normal\n",
        "from typing import List, Tuple\n",
        "\n",
        "class DeepAR(Model):\n",
        "    def __init__(self,\n",
        "                 time_steps: int,\n",
        "                 n_series: int,\n",
        "                 lstm_units: int = 64,\n",
        "                 dense_units: int = 32):\n",
        "        \"\"\"\n",
        "        DeepAR модель для множества временных рядов\n",
        "\n",
        "        Параметры:\n",
        "            time_steps: длина временного окна\n",
        "            n_series: количество уникальных рядов (по идентификаторам)\n",
        "            lstm_units: количество нейронов в LSTM слое\n",
        "            dense_units: количество нейронов в Dense слое\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.time_steps = time_steps\n",
        "        self.n_series = n_series\n",
        "\n",
        "        # Эмбеддинг для идентификаторов рядов\n",
        "        self.series_embedding = layers.Embedding(input_dim=n_series,output_dim=min(50, max(5, int(math.log2(n_series)))))\n",
        "\n",
        "        # Основная LSTM архитектура\n",
        "        self.lstm1 = layers.LSTM(lstm_units, return_sequences=True)\n",
        "        self.lstm2 = layers.LSTM(lstm_units)\n",
        "\n",
        "        # Ветви для предсказания параметров распределения\n",
        "        self.mu_head = layers.Dense(dense_units, activation='relu')\n",
        "        self.mu_out = layers.Dense(1, name='mu')\n",
        "\n",
        "        self.sigma_head = layers.Dense(dense_units, activation='relu')\n",
        "        self.sigma_out = layers.Dense(1, activation='softplus', name='sigma')  # sigma > 0\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Входные данные:\n",
        "            series_id: (batch_size,) - идентификаторы рядов\n",
        "            time_series: (batch_size, time_steps, 1) - значения рядов\n",
        "            time_features: (batch_size, time_steps, n_features) - временные фичи\n",
        "        \"\"\"\n",
        "        series_id, time_series, time_features = inputs\n",
        "\n",
        "        # Шаг 1: Добавляем информацию о ряде\n",
        "        series_emb = self.series_embedding(series_id)  # (batch_size, embed_dim)\n",
        "        series_emb = ops.expand_dims(series_emb, 1)  # (batch_size, 1, embed_dim)\n",
        "        series_emb = ops.repeat(series_emb, self.time_steps, axis=1)  # (batch_size, time_steps, embed_dim)\n",
        "\n",
        "        # Шаг 2: Объединяем все фичи\n",
        "        x = ops.concatenate([time_series, time_features, series_emb], axis=-1)\n",
        "\n",
        "        # Шаг 3: Проходим через LSTM\n",
        "        x = self.lstm1(x)\n",
        "        x = self.lstm2(x)\n",
        "\n",
        "        # Шаг 4: Предсказываем параметры распределения\n",
        "        mu = self.mu_out(self.mu_head(x))\n",
        "        sigma = self.sigma_out(self.sigma_head(x)) + 1e-6  # Избегаем нуля\n",
        "\n",
        "        return ops.concatenate([mu, sigma], axis=-1)  # (batch_size, 2)\n",
        "\n",
        "def gaussian_negative_loglikelihood(y_true, y_pred):\n",
        "    \"\"\"Функция потерь для нормального распределения\"\"\"\n",
        "    mu = y_pred[..., 0:1]\n",
        "    sigma = y_pred[..., 1:2]\n",
        "\n",
        "    return ops.mean(\n",
        "        ops.log(sigma) +\n",
        "        0.5 * ops.square((y_true - mu)/sigma) +\n",
        "        0.5 * ops.log(2 * math.pi)\n",
        "    )"
      ],
      "metadata": {
        "id": "Ov_5HbhfPAUv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # Параметры данных\n",
        "    N_SERIES = 100  # Количество уникальных рядов\n",
        "    TIME_STEPS = 24  # Длина временного окна\n",
        "    N_FEATURES = 5   # Количество временных фич\n",
        "\n",
        "    # Создаем модель\n",
        "    model = DeepAR(\n",
        "        time_steps=TIME_STEPS,\n",
        "        n_series=N_SERIES,\n",
        "        lstm_units=64\n",
        "    )\n",
        "\n",
        "    # Компилируем с кастомной функцией потерь\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(0.001),\n",
        "        loss=gaussian_negative_loglikelihood\n",
        "    )\n",
        "\n",
        "    # Пример входных данных (в реальности используйте tf.data.Dataset)\n",
        "    batch_size = 32\n",
        "    example_input = [\n",
        "        np.random.randint(0, N_SERIES, size=(batch_size,)),  # series_id\n",
        "        np.random.normal(size=(batch_size, TIME_STEPS, 1)),   # time_series\n",
        "        np.random.normal(size=(batch_size, TIME_STEPS, N_FEATURES))  # time_features\n",
        "    ]\n",
        "    example_target = np.random.normal(size=(batch_size, 1))\n",
        "\n",
        "    # Тестовый прогон\n",
        "    print(\"Тест forward pass:\")\n",
        "    output = model(example_input)\n",
        "    print(f\"Output shape: {output.shape}\")  # Должно быть (32, 2)\n",
        "\n",
        "    print(\"\\nТест обучения:\")\n",
        "    history = model.fit(\n",
        "        example_input,\n",
        "        example_target,\n",
        "        epochs=5,\n",
        "        batch_size=8\n",
        "    )"
      ],
      "metadata": {
        "id": "_7qEbZVlPGnW",
        "outputId": "e87cb7fb-a78d-422e-b2e0-3f81f8953423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тест forward pass:\n",
            "Output shape: (32, 2)\n",
            "\n",
            "Тест обучения:\n",
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 1.3332\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3503\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2756\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2964\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def history_plot(history):\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  # plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper right')\n",
        "  fig = plt.gcf()\n",
        "  plt.show()\n",
        "  # fig.savefig(f'{model_id}_{n_ahead}_loss.png')"
      ],
      "metadata": {
        "id": "LximSmYmPgdW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_plot(history)"
      ],
      "metadata": {
        "id": "8GTyAty7PiMd",
        "outputId": "4640734c-e014-4dbd-e7c0-b64737b228be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'val_loss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a8eeedfe0f50>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-758840b7141b>\u001b[0m in \u001b[0;36mhistory_plot\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# summarize history for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input[1].shape"
      ],
      "metadata": {
        "id": "1-hpZptxQOYI",
        "outputId": "9f00c8b8-18a1-49a8-ed4e-ef2624a0af91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 24, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqIA25toQ8n5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+ev8IuyRxfVEF3Iqo3sFf"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}